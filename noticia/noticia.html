
<!DOCTYPE html>
<html>
    <head> 
        <title> Meu portal de notícias</title>
    </head>
    <body> 
        <h1> IA será capaz de se reproduzir sozinha até 2028, 
            diz ex-executivo da OpenAI</h1>
<h2> Segundo Dario Amodei, que hoje é CEO da Anthropic, IAs podem ganhar habilidades 
    que representam risco para a segurança geopolítica e militar global</h2> 
    <p>
        O CEO da startup <strong>Anthropic</strong> e ex-vice-presidente de Pesquisa da <strong>OpenAI</strong>, 
        Dario Amodei, lançou um alerta que parece cena de cinema durante uma entrevista, 
        na sexta-feira (12) ao jornalista Ezra Klein, do The New York Times, 
        sobre o futuro das inteligências artificiais (IA).
    </p>  
    <p>
        Segundo Amodei, entre 2025 e 2028, as IAs poderão alcançar um nível de 
        autonomia que possibilitará sua sobrevivência e reprodução, representando assim
         um risco significativo para a segurança geopolítica e militar global.
    </p> 
    <p>
        Atualmente, a Anthropic define níveis de segurança para IAs, 
        identificados pela sigla ASL. Amodei sugere que estamos no nível 2, 
        onde os modelos de linguagem já podem fornecer informações perigosas, 
        como a <strong> construção de armas biológicas</strong>, por exemplo. Contudo, ele ressalta que essas informações 
        ainda são pouco confiáveis e representam um risco relativamente baixo.
    </p>
    <p>
        Porém, a preocupação aumenta quando se considera o potencial alcançado no nível 3, 
        que poderá ser atingido <em>já no próximo ano</em>. Neste estágio, o risco de uma catástrofe 
        seria consideravelmente maior, com a possibilidade de utilização dessas tecnologias 
        em <em>armas biológicas e cibernéticas</em>.
    </p>
    <p> <em>Fonte: CNN Brasil</em></p>

    </body>
</html>